Devansh Singh 102103686
3CO33

1.	(Gaussian Naïve Bayes Classifier) Implement Gaussian Naïve Bayes Classifier on the Iris dataset from sklearn.datasets using

        (i) Step-by-step implementation

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import numpy as np

# Load the Iris dataset
data = load_iris()
X = data.data
y = data.target

# Split into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 1: Calculate prior probabilities
priors = np.bincount(y_train) / len(y_train)

# Step 2: Calculate mean and variance for each class
mean = np.array([X_train[y_train == i].mean(axis=0) for i in range(len(priors))])
var = np.array([X_train[y_train == i].var(axis=0) for i in range(len(priors))])

# Step 3: Define Gaussian probability function
def gaussian_probability(x, mean, var):
    return (1 / np.sqrt(2 * np.pi * var)) * np.exp(-(x - mean)**2 / (2 * var))

# Step 4: Predict class
def predict(X):
    posteriors = []
    for x in X:
        post_prob = []
        for i in range(len(priors)):
            likelihood = np.prod(gaussian_probability(x, mean[i], var[i]))
            post_prob.append(priors[i] * likelihood)
        posteriors.append(np.argmax(post_prob))
    return np.array(posteriors)

# Test the model
y_pred = predict(X_test)
accuracy = np.mean(y_pred == y_test)
print(f"Accuracy: {accuracy}")

(ii) Using an In-built Function
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score

# Initialize the model
gnb = GaussianNB()

# Train the model
gnb.fit(X_train, y_train)

# Make predictions
y_pred = gnb.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

2.	Explore about GridSearchCV toot in scikit-learn. This is a tool that is often used for tuning hyperparameters of machine learning models. Use this tool to find the best value of K for K-NN Classifier using any dataset.
from sklearn.datasets import load_iris
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
import numpy as np

# Load the Iris dataset
iris = load_iris()
X = iris.data
y = iris.target

# Define the K-NN model
knn = KNeighborsClassifier()

# Define the parameter grid for 'n_neighbors' (range of K values)
param_grid = {'n_neighbors': np.arange(1, 21)}  # Testing K from 1 to 20

# Initialize GridSearchCV with 5-fold cross-validation
grid_search = GridSearchCV(knn, param_grid, cv=5)

# Fit the model to find the best K value
grid_search.fit(X, y)

# Retrieve and print the best parameter and score
best_k = grid_search.best_params_['n_neighbors']
best_score = grid_search.best_score_

print(f"Best value of K: {best_k}")
print(f"Best cross-validated accuracy: {best_score}")
